# End-to-End-Climate-Change-Model

# ğŸŒ Climate Prediction System

An end-to-end MLOps pipeline for predicting climate anomalies using machine learning, combining climate data with social media sentiment analysis.

## ğŸ“‹ Table of Contents

- [Project Overview](#project-overview)
- [Features](#features)
- [Architecture](#architecture)
- [Installation](#installation)
- [Usage](#usage)
- [Project Structure](#project-structure)
- [Configuration](#configuration)
- [Pipeline Stages](#pipeline-stages)
- [Model Performance](#model-performance)
- [API Documentation](#api-documentation)
- [Deployment](#deployment)
- [Contributing](#contributing)
- [License](#license)

## ğŸ” Project Overview

The Climate Prediction System is a comprehensive machine learning solution that predicts temperature anomalies by analyzing:

- **Climate Data**: Temperature, precipitation, CO2 concentration, sea level changes, and solar radiation
- **Social Media Sentiment**: Public opinion and engagement metrics related to climate discussions
- **Temporal Features**: Seasonal patterns, trends, and cyclical variations

### Key Objectives

- ğŸ¯ Predict temperature anomalies with high accuracy
- ğŸ“Š Combine multiple data sources for comprehensive analysis
- ğŸš€ Implement MLOps best practices for production deployment
- ğŸ“ˆ Monitor model performance and data drift
- ğŸŒ Provide user-friendly web interface for predictions

## âœ¨ Features

### Core Functionality
- **Multi-Source Data Integration**: Climate data + social media sentiment
- **Advanced Feature Engineering**: Lag features, rolling averages, seasonal decomposition
- **Ensemble Model Training**: Random Forest, XGBoost, Gradient Boosting
- **Real-time Predictions**: Web-based prediction interface
- **Model Monitoring**: Performance tracking and drift detection

### MLOps Pipeline
- **Automated Data Ingestion**: Scheduled data collection and validation
- **Data Quality Checks**: Schema validation, outlier detection, drift monitoring
- **Model Training & Evaluation**: Automated model selection and hyperparameter tuning
- **CI/CD Integration**: Automated testing and deployment

### Technical Stack
- **Backend**: Python, Flask, scikit-learn, XGBoost
- **Data Processing**: Pandas, NumPy, TextBlob
- **ML Ops**: Docker, GitHub Actions
- **Frontend**: HTML, CSS, JavaScript
- **Deployment**: AWS/Azure/GCP compatible

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Data Sources  â”‚    â”‚   Data Pipeline â”‚    â”‚   ML Pipeline   â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ Climate API   â”‚â”€â”€â”€â”€â”‚ â€¢ Ingestion     â”‚â”€â”€â”€â”€â”‚ â€¢ Training      â”‚
â”‚ â€¢ Social Media  â”‚    â”‚ â€¢ Validation    â”‚    â”‚ â€¢ Evaluation    â”‚
â”‚ â€¢ Weather Data  â”‚    â”‚ â€¢ Transform     â”‚    â”‚ â€¢ Deployment    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Monitoring    â”‚    â”‚   Model Store   â”‚    â”‚   Web App       â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ Performance   â”‚    â”‚ â€¢ Versioning    â”‚    â”‚ â€¢ Predictions   â”‚
â”‚ â€¢ Data Drift    â”‚    â”‚ â€¢ Artifacts     â”‚    â”‚ â€¢ Visualization â”‚
â”‚ â€¢ Alerts        â”‚    â”‚ â€¢ Metadata      â”‚    â”‚ â€¢ API           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Installation

### Prerequisites

- Python 3.8+
- Git
- Virtual environment tool (venv/conda)

### Setup Instructions

1. **Clone the Repository**
   ```bash
   git clone https://github.com/Durgeshsingh12712/End-to-End-Climate-Change-Model.git
   cd End-to-End-Climate-Change-Model
   ```

2. **Create Virtual Environment**
   ```bash
   python -m venv climate_env
   source climate_env/bin/activate  # On Windows: climate_env\Scripts\activate
   ```

3. **Install Dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Setup Configuration**
   ```bash
   # Create necessary directories
   mkdir -p artifacts logs config
   
   # Copy example configuration
   cp config/config.example.yaml config/config.yaml
   cp config/params.example.yaml config/params.yaml
   ```

5. **Initialize the Project**
   ```bash
   python setup.py install
   ```

### Docker Installation (Alternative)

```bash
# Build Docker image
docker build -t End-to-End-Climate-Change-Model .

# Run container
docker run -p 5000:5000 End-to-End-Climate-Change-Model
```

## ğŸ“– Usage

### Training the Model

1. **Run Complete Pipeline**
   ```bash
   python main.py
   ```

2. **Run Individual Stages**
   ```bash
   # Data ingestion
   python -m climateChange/components/data_ingestion
   
   # Data validation
   python -m climateChange/components/data_validation
   
   # Data transformation
   python -m climateChange/components/data_transformation
   
   # Model training
   python -m climateChange/components/model_trainer
   
   # Model evaluation
   python -m climateChange/components/model_evaluation
   ```

### Making Predictions

1. **Web Interface**
   ```bash
   python app.py
   # Open http://localhost:5000 in browser
   ```

2. **Python API**
   ```python
   from climateChange.pipeline.prediction_pipeline import PredictPipeline, CustomData
   
   # Create custom data
   data = CustomData(
       precipitation_anomaly=-2.5,
       co2_concentration=415.3,
       sea_level_change=3.4,
       solar_radiation=1361.2,
       year=2024,
       month=6,
       quarter=2,
       season=2,
       month_sin=0.5,
       month_cos=0.866
   )
   
   # Make prediction
   predict_pipeline = PredictPipeline()
   prediction = predict_pipeline.predict(data.get_data_as_data_frame())
   print(f"Predicted Temperature Anomaly: {prediction[0]:.3f}Â°C")
   ```

## ğŸ“ Project Structure

```
climate_prediction/
â”œâ”€â”€ ğŸ“‚ src/climate_prediction/
â”‚   â”œâ”€â”€ ğŸ“‚ components/          # Core ML components
â”‚   â”‚   â”œâ”€â”€ data_ingestion.py
â”‚   â”‚   â”œâ”€â”€ data_validation.py
â”‚   â”‚   â”œâ”€â”€ data_transformation.py
â”‚   â”‚   â”œâ”€â”€ model_trainer.py
â”‚   â”‚   â””â”€â”€ model_evaluation.py
â”‚   â”œâ”€â”€ ğŸ“‚ configure/              # Configuration management
â”‚   â”‚   â””â”€â”€ configuration.py
â”‚   â”œâ”€â”€ ğŸ“‚ entity/              # Data classes
â”‚   â”‚   â”œâ”€â”€ config_entity.py
â”‚   â”‚   â””â”€â”€ artifact_entity.py
â”‚   â”œâ”€â”€ ğŸ“‚ pipeline/            # Pipeline stages
â”‚   â”‚   â”œâ”€â”€ trainining_pipeline.py
â”‚   â”‚   â””â”€â”€ predict_pipeline.py
â”‚   â”œâ”€â”€ ğŸ“‚ utils/               # Utility functions
â”‚   â”‚   â””â”€â”€ tools.py
â”‚   â”œâ”€â”€ ğŸ“‚ constants/           # Project constants
â”‚   â”‚   â””â”€â”€constant.py        
â”‚   â”œâ”€â”€ ğŸ“‚ loggers/             # Logging configuration
â”‚   â”‚   â””â”€â”€logger.py
â”‚   â”œâ”€â”€ ğŸ“‚ exception/           # Custom Climate CHange Exception
        â””â”€â”€CCException.py

â”œâ”€â”€ ğŸ“‚ config/                  # Configuration files
â”‚   â”œâ”€â”€ config.yaml
â”‚   â””â”€â”€ params.yaml
â”œâ”€â”€ ğŸ“‚ templates/               # Web templates
â”‚   â”œâ”€â”€ index.html
â”‚   â””â”€â”€ home.html
â”‚   â””â”€â”€ base.html
â”‚   â””â”€â”€ about.html
â”œâ”€â”€ ğŸ“‚ artifacts/               # Generated artifacts
â”œâ”€â”€ ğŸ“‚ logs/                    # Log files
â”œâ”€â”€ ğŸ“„ app.py                   # Flask web application
â”œâ”€â”€ ğŸ“„ main.py                  # Main training pipeline
â”œâ”€â”€ ğŸ“„ requirements.txt         # Dependencies
â”œâ”€â”€ ğŸ“„ setup.py                 # Package setup
â”œâ”€â”€ ğŸ“„ Dockerfile              # Docker configuration
â””â”€â”€ ğŸ“„ README.md               # This file
```

## âš™ï¸ Configuration

### config.yaml
```yaml
# Main configuration file
artifacts_root: artifacts

data_ingestion:
  root_dir: artifacts/data_ingestion
  climate_data_url: https://climate.nasa.gov/api/temperature-data
  social_data_url: https://api.github.com/repos/nasa/climate-data

model_trainer:
  root_dir: artifacts/model_trainer
  model_name: climate_predictor
  
```

### params.yaml
```yaml
# Model parameters
TEST_SIZE: 0.2
RANDOM_STATE: 42
TARGET_COLUMN: temperature_anomaly

model_params:
  RandomForestRegressor:
    n_estimators: [50, 100, 200]
    max_depth: [5, 10, 15, null]
  XGBRegressor:
    n_estimators: [50, 100, 200]
    learning_rate: [0.05, 0.1, 0.2]
```

## ğŸ”„ Pipeline Stages

### 1. Data Ingestion
- **Purpose**: Collect climate and social media data
- **Input**: External APIs, databases
- **Output**: Raw CSV files
- **Features**:
  - Automated data collection
  - Data format validation
  - Error handling and retry logic

### 2. Data Validation  
- **Purpose**: Ensure data quality and consistency
- **Input**: Raw data files
- **Output**: Validation report
- **Checks**:
  - Schema validation
  - Missing value analysis
  - Outlier detection
  - Data drift monitoring

### 3. Data Transformation
- **Purpose**: Feature engineering and preprocessing
- **Input**: Validated data
- **Output**: Processed features, preprocessor object
- **Operations**:
  - Time series feature creation
  - Sentiment analysis
  - Scaling and encoding
  - Train-test splitting

### 4. Model Training
- **Purpose**: Train and select best performing model
- **Input**: Processed features
- **Output**: Trained model, metrics
- **Models**:
  - Random Forest Regressor
  - XGBoost Regressor
  - Gradient Boosting Regressor
  - Linear Regression

### 5. Model Evaluation
- **Purpose**: Evaluate model performance and log metrics
- **Input**: Trained model, test data
- **Output**: Evaluation metrics
- **Metrics**:
  - Mean Absolute Error (MAE)
  - Root Mean Square Error (RMSE)
  - RÂ² Score
  - Mean Absolute Percentage Error (MAPE)

## ğŸ“Š Model Performance

### Current Best Model: XGBoost Regressor

| Metric | Train | Test |
|--------|--------|------|
| MAE    | 0.145  | 0.167 |
| RMSE   | 0.198  | 0.234 |
| RÂ²     | 0.887  | 0.854 |
| MAPE   | 8.2%   | 9.7%  |

### Feature Importance

1. **CO2 Concentration** (23.4%)
2. **Temperature Trend** (18.7%)
3. **Seasonal Features** (15.2%)
4. **Solar Radiation** (12.8%)
5. **Social Sentiment** (11.3%)

## ğŸ”Œ API Documentation

### Prediction Endpoint

```http
POST /predictdata
Content-Type: application/x-www-form-urlencoded

precipitation_anomaly=-2.5&co2_concentration=415.3&sea_level_change=3.4...
```

### Response Format

```json
{
  "prediction": 1.234,
  "status": "success",
  "model_version": "v1.0.0",
  "confidence": 0.89
}
```

### Web Interface

Access the web interface at `http://localhost:5000` for:
- Interactive prediction form
- Real-time results
- Visualization dashboard
- Model performance metrics

## ğŸš€ Deployment

### Local Development
```bash
python app.py
# Access at http://localhost:5000
```

### Production Deployment

#### Docker
```bash
docker build -t End-to-End-Climate-Change-Model .
docker run -p 5000:5000 -e PORT=5000 End-to-End-Climate-Change-Model
```

#### Cloud Platforms

**AWS ECS/Fargate**
```bash
# Build and push to ECR
aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin
docker tag End-to-End-Climate-Change-Model:latest <account>.dkr.ecr.us-east-1.amazonaws.com/End-to-End-Climate-Change-Model:latest
docker push <account>.dkr.ecr.us-east-1.amazonaws.com/End-to-End-Climate-Change-Model:latest
```

**Google Cloud Run**
```bash
gcloud builds submit --tag gcr.io/PROJECT-ID/End-to-End-Climate-Change-Model
gcloud run deploy --image gcr.io/PROJECT-ID/End-to-End-Climate-Change-Model --platform managed
```

### Environment Variables

```bash
# Required for production
export MODEL_REGISTRY_URI="your-model-registry"
export DATA_SOURCE_API_KEY="your-api-key"
```

## ğŸ”§ Development

### Setting up Development Environment

1. **Install development dependencies**
   ```bash
   pip install -r requirements-dev.txt
   ```

2. **Pre-commit hooks**
   ```bash
   pre-commit install
   ```

3. **Run tests**
   ```bash
   pytest tests/ -v --cov=src/End-to-End-Climate-Change-Model
   ```

4. **Code formatting**
   ```bash
   black src/
   isort src/
   flake8 src/
   ```

### Adding New Features

1. Create feature branch: `git checkout -b feature/new-feature`
2. Implement changes following project structure
3. Add tests for new functionality
4. Update documentation
5. Submit pull request

## ğŸ“ˆ Monitoring & Maintenance

### Model Monitoring
- **Performance Tracking**: Automated metrics collection
- **Data Drift Detection**: Statistical tests for input distribution changes
- **Prediction Drift**: Monitor prediction distribution over time
- **Alerting**: Email/Slack notifications for issues

### Maintenance Tasks
- **Weekly**: Review model performance metrics
- **Monthly**: Check for data drift and retrain if needed
- **Quarterly**: Evaluate new features and model architectures

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details.

### Ways to Contribute
- ğŸ› Report bugs and issues
- ğŸ’¡ Suggest new features
- ğŸ“ Improve documentation
- ğŸ”§ Submit code improvements
- ğŸ§ª Add test cases

### Contribution Process
1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests and documentation
5. Submit a pull request

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **NASA Climate Change APIs** for providing climate data
- **NOAA** for weather and atmospheric data
- **scikit-learn** community for machine learning tools
- **MLflow** for experiment tracking capabilities

## ğŸ“ Support

- **Documentation**: [Project Wiki](https://github.com/Durgeshsingh12712/End-to-End-Climate-Change-Model/wiki)
- **Issues**: [GitHub Issues](https://github.com/Durgeshsingh12712/End-to-End-Climate-Change-Model/issues)
- **Discussions**: [GitHub Discussions](https://github.com/Durgeshsingh12712/End-to-End-Climate-Change-Model/discussions)
- **Email**: durgeshsingh12712@gmail.com

---

<div align="center">

**ğŸŒ Building a sustainable future through predictive analytics ğŸŒ**

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![ML](https://img.shields.io/badge/ML-scikit--learn-orange.svg)
![Status](https://img.shields.io/badge/Status-Active-green.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)

</div>